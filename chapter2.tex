\section{Глава 2}

\subsection{Набор данных}

В целях исследования итеративного процесса томографии под контролем реконструкции с точки зрения качества сегментации необходимы следующие компоненты:
\begin{enumerate}

    \item Набор данных, на которых проводятся эксперименты.
    \item Алгоритмы сегментации.
    \item Метрики для оценки качества сегментации.
        
\end{enumerate}   

Рассмотрим первую компоненту - входной набор данных.

Под набором данных, в рамках данной работы, подрозумевается множество из \(n\) изображений \( (\image)_1, (\image)_2, \ldots, (\image)_n \). 

В целях простоты у всех изображения набора данных одинаковый размер.

Такое упрощение позволит сосредоточиться на вопросе останова в итеративном процесссе томографии под контролем реконструкции, пропустив этап подбора параметров реконструкции отдельно для каждого изображения в наборе данных.

Основной целью работы является исследование правила останова в итеративной томографии под контролем реконструкции. Поэтому набор данных должен моделировать различные варианты соотношения между углами сканирования и угловой структурой изображений.

Большинство изображений  в наборе данных являются синтетическими и были сгенерированы с помощью языка программирования Python.

Набор данных состоит из 8 изображений, сгруппированных по 2 на основе схожести моделируемой угловой структуры.

Все изображения набора данных имеют размер \(n = (256, 512, 512)\).

Первая пара представляет собой два изображения реконструкции бетонных плит, предоставленные в работе \cite{wagner2023comparative}.

Изображение "Бетон-1" содержит характерные горизонтально ориентированные дефекты, интерпретируемые как трещины. На рисунке~\ref{fig:concrete1} приведён один из срезов: слева реконструкция, справа — эталонная бинарная маска.

\gostfigure{concrete1}{Срез 128 бинарной маски изображение "Бетон-1" }{concrete1}

Изображение "Бетон-2" представляет собой бетонную плиту с дефектом типа раковина - пустое пространство внутри плиты.

На рисунке~\ref{fig:concrete2} приведен срез изображения реконструкции "Бетон-2" и соответствующий ему срез бинарной маски.


\gostfigure{concrete2}{Срез 128 бинарной маски изображение "Бетон-2" }{concrete2}

В этих изображениях стоит отметить преобладание объекта над фоном по количеству пикселей.

Следующей парой объектов в наборе данных являются синтетические изображения трёхмерной решётки, сформированной пересекающимися семействами параллельных плоскостей. 

В одном случае решётка строго ортогональна координатным осям. Это изображение в дальнейшем обозначается как "Решётка". На рисунке~\ref{fig:grid} представлен срез её реконструкции и соответствующий срез эталонной бинарной маски.

Такой объект включён в набор данных как модель идеального случая: углы ориентации структур внутри объекта полностью совпадают с начальными углами сканирования в процессе томографии под контролем реконструкции.

\gostfigure{grid}{Срез 128 бинарной маски изображение "Решетка"}{grid}

Вторая решётка, обозначаемая как "Наклонная решётка", формируется по тому же принципу, что и предыдущая, но все её плоскости наклонены относительно координатных осей.

!!TODO добавить конкретные углы на которые конструкция наклонена!!

Соответствующие срезы реконструкции и эталона приведены на рисунке~\ref{fig:anglegrid}.

Данный объект моделирует случай, когда начальный набор углов сканирования не совпадает с ориентацией внутренних структур объекта. При этом число таких ориентаций ограничено: решётка состоит из трёх групп плоскостей, каждая из которых наклонена под фиксированным углом.

Ожидается, что при включении в процесс реконструкции проекций под соответствующими углами произойдёт резкое улучшение качества бинаризации.

\gostfigure{anglegrid}{Срез 128 бинарной маски изображения "Наклонная решётка"}{anglegrid}

\subsection{Алгоритмы сегментации в экспериментах}

С учётом необходимости многократного применения в процессе итеративной реконструкции, для экспериментов были выбраны пороговые алгоритмы, как простые, устойчивые и не требующие сложной настройки.

Основная идея пороговых алгоритмов достаточно проста. 

Пусть дано изображение \(\image\) размера \(n = (n_1, n_2, n_3)\).

Выходом алгоритма будет сегментация \(\tilde{\image}\) изображения \(\image\), совпадающая размером с исходным изображением.

Значение каждого пикселя сегментации \(\tilde{\image}\) определяется по следующей формуле:

\begin{equation}
    \tilde{\image} (i, j, k) = 
    \begin{cases}
        1, \image(i, j, k) \geq t\\
        0, \image(i, j, k) < t
    \end{cases}
\end{equation}

Соответственно в сегментации пиксель \((i, j, k)\) классифицируется как объект если значение исходного изображения в этом пикселе имеет значение больше или равное некоторому порогу \(t\), иначе этот пиксель классифицируется как фон.

В зависимости от характера порога \(t\) выделяют глобальные и локальные пороговые алгоритмы.

В глобальном случае порог не зависит от пикселя, соответственно все пиксели сравниваются с одним значением порога.

Такими алгоритмами являются классический пороговый алгоритм и алгоритм Отсу.

В классическом пороговом алгоритме порог является параметром, соответственно он требует его априорной оценки.

Алгоритм Отсу \cite{otsu1975threshold} определяет оптимальное значение порога \(t\), максимизируя межклассовую дисперсию:

\begin{equation}
    \sigma^2(t) = \omega_0(t) \omega_1(t) \left[ \mu_0(t) - \mu_1(t) \right]^2,
\end{equation}

где \(\omega_0(t)\) и \(\omega_1(t)\) — вероятности (доли) фона и объекта при пороге \(t\), а \(\mu_0(t)\) и \(\mu_1(t)\) — соответствующие средние значения интенсивности.

Алгоритм перебирает возможные значения \(t\) и выбирает то, при котором значение \(\sigma^2(t)\) максимизируется. 

Локальные пороговые алгоритмы определяют порог для каждого пикселя, соотвественно порог \(t\) становится функцией от пикселя \(t = t(i, j, k)\).

Распрастраненным локальным пороговым алгоритмом является метод Ниблэка \cite{niblack1985introduction}.

Алгоритм Ниблэка определяет порог \(t\) для пикселя \((i, j, k)\) по следующей формуле:

\begin{equation} \label{eq:niblack}
    t(i, j, k) = \mu_r(i, j, k) + k \sigma_r(i, j, k)
\end{equation}

где \(\mu_r(i, j, k)\) и \(\sigma_r(i, j, k)\) - среднее и среднеквадратичное отклонение интенсивности в окрестности \(r\) пикселя \((i, j, k)\).

В общем случае среднее и среднеквадратичное отклонение в \\ окрестности \(r\) пикселя \((i, j, k)\) рассчитываются по следующим формулам:

\begin{equation}\label{eq:niblack_mean}
    \mu_r(i, j, k) = \frac{1}{(2r + 1)^3} \sum_{x = i - r}^{i + r} \sum_{y = j - r}^{j + r} \sum_{z = k - r}^{k + r} \image(x, y, z)
\end{equation}

\begin{equation}\label{eq:niblack_std}
    \sigma_r(i, j, k) = \sqrt{\frac{1}{(2r + 1)^3} \sum_{x = i - r}^{i + r} \sum_{y = j - r}^{j + r} \sum_{z = k - r}^{k + r} (\image(x, y, z) - \mu_r(i, j, k))^2}
\end{equation}

Соответственно окном является куб с длинной сторон \(2r + 1\). 

Проблемной частью формул \ref{eq:niblack_mean} и \ref{eq:niblack_std} является ситуация, когда окно частично выходит за границы изображения.

В таких случаях применяются следующие стратегии обработки:

\begin{enumerate}
    \item \textbf{Обрезка окна по границам.} Вычисления проводятся только по той части окна, которая полностью попадает внутрь изображения.
    
    \item \textbf{Задание фиксированного значения.} За пределами изображения значения пикселей считаются равными фиксированной константе, например, нулю или среднему значению изображения.
    
    \item \textbf{Отражение по границе.} Отсутствующие значения заполняются за счёт зеркального отражения пикселей относительно соответствующей границы изображения.
\end{enumerate}

У каждой стратегии есть свои преимущества и недостатки. Её выбор зависит от характера входных изображений.

У классического алгоритма Ниблэка существует множетсо модификаций.

Такими модификациями являются, например, алгоритмы Сауволы \ref{sauvola2000adaptive} и Фансалкара \ref{phansalkar2011adaptive}.

В рамках данной работы выбрана аффинный вариант алгоритма Ниблэка, описанный в работе \ref{николаев2013критерии}.

Суть 

