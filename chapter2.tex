\section{Подготовка материалов, проектирование и реализация конвейера экспериментов}

В данной главе будет описан процесс подготовки входных данных, выбран набор алгоритмов бинаризации, проведён анализ метрик качества на модельных ошибках и сформирован итоговый набор. Затем будет спроектирован и реализован программный конвейер экспериментов, включающий этапы реконструкции, бинаризации, оценки и визуализации результатов.

\subsection{Подготовка набора данных для экспериментов}

В целях исследования итеративного процесса томографии под контролем реконструкции с точки зрения качества сегментации необходимы следующие компоненты:
\begin{enumerate}
    \item Набор данных, на которых проводятся эксперименты.
    \item Алгоритмы сегментации.
    \item Метрики для оценки качества сегментации.
\end{enumerate}   

Рассмотрим первую компоненту — входной набор данных.

Под набором данных в рамках данной работы подразумевается множество из \(n\) изображений \( (\image)_1, (\image)_2, \ldots, (\image)_n \). 

Так как основной целью работы является исследование правила останова в итеративной томографии под контролем реконструкции, набор данных должен моделировать различные варианты соотношения между углами сканирования и угловой структурой изображений.

Большинство изображений в наборе данных являются синтетическими и были сгенерированы с помощью языка программирования Python.

Набор данных состоит из десяти изображений, сгруппированных по два на основе схожести моделируемой угловой структуры.

Первые 4 пары изображений имеют одинаковый размер — 256 срезов, каждый из которых \(512 \times 512\) пикселей. Объём каждого изображения соответственно имеет размер \(512 \times 512 \times 256\).

Первая пара представляет собой два изображения реконструкции бетонных плит, предоставленные в работе \cite{wagner2023comparative}.

Изображение ``Бетон-1'' содержит характерные горизонтально ориентированные дефекты, интерпретируемые как трещины. На рисунке~\ref{fig:concrete1} приведён срез этого изображения и его трёхмерная визуализация.

\gostfigure{concrete1}{Изображение реконструкции ``Бетон-1''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{concrete1}

Изображение ``Бетон-2'' представляет собой бетонную плиту с дефектом типа ``раковина'' (пустое пространство внутри плиты).

На рисунке~\ref{fig:concrete2} приведён срез изображения ``Бетон-2'' и соответствующая трёхмерная модель.

\gostfigure{concrete2}{Изображение реконструкции ``Бетон-2''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{concrete2}

В этих изображениях стоит отметить преобладание объекта над фоном по количеству пикселей.

Следующей парой объектов в наборе данных являются синтетические изображения трёхмерной решётки, сформированной пересекающимися семействами параллельных плоскостей. 

В одном случае решётка строго ортогональна координатным осям. Это изображение в дальнейшем обозначается как ``Решётка''. На рисунке~\ref{fig:grid} представлен срез её реконструкции и объёмная модель.

Такой объект включён в набор данных как модель идеального случая: углы ориентации структур внутри объекта полностью совпадают с начальными углами сканирования в процессе томографии под контролем реконструкции, соответственно процесс должен остановиться уже при небольшом количестве проекций.

\gostfigure{grid}{Изображение реконструкции ''Решётка''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{grid}

Вторая решётка, обозначаемая как ''Наклонная решётка'', формируется по тому же принципу, что и предыдущая, но все её плоскости наклонены относительно координатных осей.

Каждое семейство плоскостей в этой решётке изначально было ортогонально одному из направлений декартовой системы координат. Затем к каждому семейству был применён поворот вокруг одной из осей: первое семейство — на угол \(1{,}31\) радиан вокруг оси \(X\), второе — на угол \(0{,}13\) радиан вокруг оси \(Y\), третье — на угол \(1{,}31\) радиан вокруг оси \(Z\).

Срез изображения и трёхмерная визуализация приведены на рисунке~\ref{fig:anglegrid}.

Данный объект моделирует случай, когда начальный набор углов сканирования не совпадает с ориентацией внутренних структур объекта. При этом число таких ориентаций ограничено: решётка состоит из трёх групп плоскостей, каждая из которых наклонена под фиксированным углом.

Ожидается, что при включении в процесс реконструкции проекций под соответствующими углами произойдёт резкое улучшение качества бинаризации.

\gostfigure{anglegrid}{Изображение реконструкции ''Наклонная решётка''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{anglegrid}

Далее рассмотрим пару синтетических изображений, содержащих объекты с плавными очертаниями, без резких переходов или острых углов.

В отличие от структур с резкими границами, для них не ожидается резкого скачка качества при включении определённых углов сканирования — качество улучшается постепенно с включением большего количества проекций.

Первое изображение из этой пары — ''Эллипсы''. Оно представляет собой объём, разделённый на 27 параллелепипедов, в каждый из которых вписан трёхмерный эллипсоид. Размеры эллипсоидов варьируются, и в случае, если фигура не помещается в отведённую область, её выходящие за границы части отсекаются.

Срез и трёхмерная визуализация этого изображения представлены на рисунке~\ref{fig:ellipses}.

\gostfigure{ellipses}{Изображение реконструкции ''Эллипсы''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{ellipses}

Вторым изображением из данной пары является ''Гауссиана''. Оно представляет собой синтетическую трёхмерную структуру, состоящую из двух объёмных образований, форма которых аппроксимирует гауссовы колокола.

Первая фигура расположена в нижней части объёма, начинаясь с плоскости \(z = 0\), и ориентирована так, что её максимум находится вблизи центра, а ось симметрии направлена вверх. Вторая фигура начинается с верхней части объёма, от плоскости \(z = 255\), и ориентирована в противоположную сторону — вниз.

Обе фигуры подвергнуты повороту: первая — вокруг оси \(x\), вторая — вокруг оси \(y\). Угол поворота в обоих случаях составляет \(\frac{\pi}{22}\) радиан.

Рисунок~\ref{fig:gaussian} иллюстрирует изображение ''Гауссиана'': слева показан его срез, справа — трёхмерная визуализация.

\gostfigure{gaussian}{Изображение реконструкции ''Гауссиана''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{gaussian}

Следующая пара синтетических изображений является противоположностью предыдущей — состоит из резких углов и ровных линий.

У таких изображений ожидаются скачки в качестве реконструкции при включении проекций под соответствующими углами. В отличие от пары ''Решётка'' и ''Наклонная решётка'', таких скачков может быть несколько, поскольку изображение содержит несколько трёхмерных объектов с различными ориентациями.

В состав изображения входят две пересекающиеся пирамиды: одна с прямоугольным основанием, другая — с треугольным. Оси симметрии пирамид ориентированы по-разному: первая повёрнута вокруг оси \(z\), вторая — вокруг оси \(y\). 

В дополнение к ним в свободное пространство между пирамидами встроен трёхмерный гексагон, не пересекающийся с другими объектами. Все фигуры размещены в объёме случайным образом, что исключает регулярность и добавляет сложности к реконструкции.

В случае первого изображения ''Полигоны-1'', приведённого на рисунке~\ref{fig:polygon1}, пирамида с прямоугольным основанием имеет поворот вокруг оси \(z\) на угол \(1{,}005\) радиан, а пирамида с треугольным основанием имеет угол поворота вокруг оси \(y\), равный \(2{,}89\) радиан.

\gostfigure{polygon1}{Изображение реконструкции ''Полигоны-1''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{polygon1}

Второе изображение — ''Полигоны-2'' — проиллюстрировано на рисунке~\ref{fig:polygon2}. В нём пирамида с прямоугольным основанием повёрнута вокруг оси \(z\) на угол \(4{,}71\) радиан, а пирамида с треугольным основанием — вокруг оси \(y\) на угол \(2{,}89\) радиан.

\gostfigure{polygon2}{Изображение реконструкции ''Полигоны-2''; а — срез трёхмерного изображения, б — трёхмерная визуализация}{polygon2}

Последней парой изображений являются трехмерные модели построенные из изображений реконструкции при сканировании  объектов с помощью сканнера  Cyberware 3030 MS в лаборатории компьютерной графики Стэнфордского университета \cite{stanfordRepository}.

Данные изображения представляют собой сканы реальных объектов с высокой геометрической детализацией, что позволяет оценить поведение правила останова на данных, приближённых к практическим условиям применения.

Первым изображением из данной пары, которое назовем ''Кролик'', является скан фигурки кролика и состоит из 100 срезов размером \(128 \times 129\), соответственно размер объема \(128 \times 129 \times 100\).

Один из срезов изображения и его трехмерная визуализация представлены в рисунке~\ref{fig:bunny}.

Фигурка является полой, соответственно особенность данного изображения является преобладание объекта над фоном. Это делает данное изображение противоположностью изображений ''Бетон-1'' и ''Бетон-2''.

\gostfigure{bunny}{Изображение реконструкции ''Кролик''; а - срез трёхмерного изображения, б - трехмерная визуализация}{bunny}

Последним изображением является скан небольшой тайской статуэтки и представлено на рисунке~\ref{fig:statue}. Трехмерное изображение формируется из 132 срезов размером \(257 \times 153\) пикселей, соответственно полный объём имеет размер \(257 \times 153 \times 132\) пикселя.

Её особенностью являются достаточно сложные границы объекта. В отличие от изображения ''Кролик'', данное изображение, которое назовем ''Тайская статуэтка'', не является полой.

\gostfigure{statue}{Изображение реконструкции ''Тайская статуэтка''; а - срез трёхмерного изображения, б - трехмерная визуализация}{statue}

Собранный набор данных, состоящий из десяти изображений с разнообразной структурой, охватывает широкий спектр сценариев, возникающих при томографической реконструкции: от регулярных и идеально выровненных структур до объектов с произвольной ориентацией и сложной геометрией.

Такой набор данных формирует основу исследования, поскольку исследование эффективности правила останова возможно лишь на сбалансированном наборе данных. 

Далее будем рассматривать остальные компоненты, необходимые для конвейера основных экспериментов.

\subsection{Выбор алгоритмов сегментации для проведения экспериментов}

С учётом необходимости многократного применения в процессе итеративной реконструкции, для экспериментов были выбраны пороговые алгоритмы, как простые, устойчивые и не требующие сложной настройки.

Основная идея пороговых алгоритмов достаточно проста. 

Пусть дано изображение \(\image\) размера \(n = (n_1, n_2, n_3)\).

Выходом алгоритма будет сегментация \(\tilde{\image}\) изображения \(\image\), совпадающая размером с исходным изображением.

Значение каждого пикселя сегментации \(\tilde{\image}\) определяется по следующей формуле:

\begin{equation} \label{eq:classicthresholding}
    \tilde{\image} (i, j, k) = 
    \begin{cases}
        1, \image(i, j, k) \geq t\\
        0, \image(i, j, k) < t
    \end{cases}
\end{equation}

Соответственно, в сегментации пиксель \((i, j, k)\) классифицируется как объект если значение исходного изображения в этом пикселе имеет значение больше или равное некоторому порогу \(t\), иначе этот пиксель классифицируется как фон.

В зависимости от характера порога \(t\) выделяют глобальные и локальные пороговые алгоритмы.

В глобальном случае порог не зависит от пикселя, соответственно все пиксели сравниваются с одним значением порога.

Такими алгоритмами являются классический пороговый алгоритм и алгоритм Отсу.

В классическом пороговом алгоритме порог является параметром, соответственно он требует его априорной оценки.

Алгоритм Отсу \cite{otsu1975threshold} определяет оптимальное значение порога \(t\), максимизируя межклассовую дисперсию:

\begin{equation}
    \sigma^2(t) = \omega_0(t) \omega_1(t) \left[ \mu_0(t) - \mu_1(t) \right]^2,
\end{equation}

где \(\omega_0(t)\) и \(\omega_1(t)\) — вероятности (доли) фона и объекта при пороге \(t\), а \(\mu_0(t)\) и \(\mu_1(t)\) — соответствующие средние значения интенсивности.

Алгоритм перебирает возможные значения \(t\) и выбирает то, при котором значение \(\sigma^2(t)\) максимизируется. 

Локальные пороговые алгоритмы определяют порог для каждого пикселя, соотвественно порог \(t\) становится функцией от пикселя \(t = t(i, j, k)\).

Распрастраненным локальным пороговым алгоритмом является метод Ниблэка \cite{niblack1985introduction}.

Алгоритм Ниблэка определяет порог \(t\) для пикселя \((i, j, k)\) по следующей формуле:

\begin{equation} \label{eq:niblack}
    t(i, j, k) = \mu_r(i, j, k) + k \sigma_r(i, j, k)
\end{equation}

где \(\mu_r(i, j, k)\) и \(\sigma_r(i, j, k)\) - среднее и среднеквадратичное отклонение интенсивности в окрестности \(r\) пикселя \((i, j, k)\).

В общем случае среднее и среднеквадратичное отклонение в \\ окрестности \(r\) пикселя \((i, j, k)\) рассчитываются по следующим формулам:

\begin{equation}\label{eq:niblack_mean}
    \mu_r(i, j, k) = \frac{1}{(2r + 1)^3} \sum_{x = i - r}^{i + r} \sum_{y = j - r}^{j + r} \sum_{z = k - r}^{k + r} \image(x, y, z)
\end{equation}

\begin{equation}\label{eq:niblack_std}
    \sigma_r(i, j, k) = \sqrt{\frac{1}{(2r + 1)^3} \sum_{x = i - r}^{i + r} \sum_{y = j - r}^{j + r} \sum_{z = k - r}^{k + r} (\image(x, y, z) - \mu_r(i, j, k))^2}
\end{equation}

Соответственно окном является куб с длинной сторон \(2r + 1\). 

Проблемной частью формул \ref{eq:niblack_mean} и \ref{eq:niblack_std} является ситуация, когда окно частично выходит за границы изображения.

В таких случаях применяются следующие стратегии обработки:

\begin{enumerate}
    \item \textbf{Обрезка окна по границам.} Вычисления проводятся только по той части окна, которая полностью попадает внутрь изображения.
    
    \item \textbf{Задание фиксированного значения.} За пределами изображения значения пикселей считаются равными фиксированной константе, например, нулю или среднему значению изображения.
    
    \item \textbf{Отражение по границе.} Отсутствующие значения заполняются за счёт зеркального отражения пикселей относительно соответствующей границы изображения.
\end{enumerate}

У каждой стратегии есть свои преимущества и недостатки. Её выбор зависит от характера входных изображений.

У классического алгоритма Ниблэка существует множетсо модификаций.

Такими модификациями являются, например, алгоритмы Сауволы \cite{sauvola2000adaptive} и Фансалкара \cite{phansalkar2011adaptive}.

В рамках данной работы выбран аффинный вариант алгоритма Ниблэка, описанный в работе \cite{николаев2013критерии}.

Метод аффинного Ниблэка добавляет в уравнение \ref{eq:niblack} дополнительный параметр \(beta\), который является глобальной оценкой шума.

\begin{equation}\label{eq:niblack_affine}
    t(i, j, k) = \mu_r(i, j, k) + \sigma_r(i, j, k) + \beta
\end{equation}

Такая модификация является вычислительно эффективной так как к формуле добавляется константа, однако она добавляет дополнительный параметр. 

Таким образом, итоговый набор алгоритмов, используемых в конвейере экспериментов, включает в себя:

\begin{enumerate}
    \item Классический пороговый алгоритм
    \item Алгоритм Отсу
    \item Алгоритм аффинного Ниблека
\end{enumerate}

Выбор данных алгоритмов обусловлен их высокой степенью изученности в литературе и активным применением в задачах компьютерной томографии.

Поскольку алгоритм бинаризации запускается на каждой итерации томографии под контролем реконструкции, его вычислительная эффективность напрямую влияет на общую скорость всего процесса.

Следующей необходимой для экспериментов компонентой являются метрики, позволяющие оценить качество полученных бинарных масок.

\subsection{Формирование набора метрик на основе численных экспериментов по оценке их чувствительности}

Последним необходимым элементом экспериментального конвейера является набор метрик оценки качества сегментации.

Метрики должны быть подобраны так, чтобы в совокупности охватывать ключевые аспекты качества бинарных масок — например, точность границ и степень перекрытия с эталоном. 

Такой набор метрик должен выявлять различные типы ошибок и предоставлять более объективную оценку результата.

Хотя в области машинного обучения и компьютерного зрения существует множество метрик, не все из них применимы к задачи сегментации изображений. 

Например, метрики, ориентированные на числовые значения, текстовые последовательности или графовые структуры, не учитывают пространственные особенности изображений и потому неинформативны в контексте сегментации.

Среди метрик, предназначенных для работы с изображениями, встречается избыточность: несколько показателей могут быть чувствительны к одним и тем же видам ошибок.

В конвейер экспериментов требуется сформировать минимально необходимый набор  метрик, который позволит обнаружить распрастраненные типы ошибок.

Чтобы выбрать такой набор метрик обоснованно, необходимо провести серию экспериментов на модельных данных.

Такие эксперименты позволят изучить поведение метрик при различных типах ошибок.

Для реализации таких экспериментов необходимы следующие шаги:

\begin{enumerate}
    \item Собрать начальный набор метрик для исследования.
    \item Определить набор ошибок, которые должны обнаружить метрики.
    \item Сформировать модельные изображения для набора ошибок
\end{enumerate}

Часть метрик для начального набора были найдены в работе \cite{taha2015metrics}. Авторы данного исследования изложили распрастраненные метрики, применяемые в оценки качества сегментации изображений реконструкции в медицине.

Из таких метрик в начальный набор данных будут включены метрики DICE, Intersection Over Union (IOU), Mean Square Error (MSE).

Пусть даны эталонная бинарная маска \((\tilde{\image})_{gt}\) изображения и его сегментация \((\tilde{\image})_{seg}\).

Обозначим как \((\tilde{\image})_{gt} \cap (\tilde{\image})_{seg}\) множество пикселей, на которых значение сегментации и эталонной бинарной маски совпадают и равно 1: \((\tilde{\image})_{gt} \cap (\tilde{\image})_{seg} := |\{x \in P | (\tilde{\image})_{gt}(x) = (\tilde{\image})_{seg}(x) = 1 \}|\).

Определим также \((\tilde{\image})_{gt} \cup (\tilde{\image})_{seg}\) как множество пикселей, на которых значение сегментации или эталонной бинарной маски  равно 1: \((\tilde{\image})_{gt} \cup (\tilde{\image})_{seg} := |\{x \in P | (\tilde{\image})_{gt}(x) = 1 \lor (\tilde{\image})_{seg}(x) = 1 \}|\).

Тогда метрика DICE определяется как следующей формулой:

\begin{equation}\label{eq:DICE}
    DICE((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) =
    \frac{2 \cdot \left|(\tilde{\image})_{gt} \cap (\tilde{\image})_{seg}\right|}
         {\left|(\tilde{\image})_{gt}\right| + \left|(\tilde{\image})_{seg}\right|}
\end{equation}
где \(\left|(\tilde{\image})\right|\) является мощностью множества пикселей, на которых  маска \((\tilde{\image})\) имеет значение 1: \(\left|(\tilde{\image})\right| = |\{x \in P | (\tilde{\image})(x) = 1 \}|\).

Метрика DICE принимает значения в отрезке от 0 до 1, где 0 - полное несовпадение изображений, а 1 - их полное совпадение.

Индекс DICE является одной из классических метрик перекрытия — класса метрик, которые измеряют степень пересечения двух множеств (в данном случае бинарных масок). 

Другой растрастраненной метрикой перекрытия является IOU, также известная как метрика Жаккарда. Она определяется слудующей формулой:

\begin{equation}\label{eq:IOU}
    IOU((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) =
    \frac{\left|(\tilde{\image})_{gt} \cap (\tilde{\image})_{seg}\right|}
         {\left|(\tilde{\image})_{gt} \cup (\tilde{\image})_{seg}\right|}
\end{equation}

Аналогично метрики DICE, значения IOU находятся в отрезке от 0 до 1, где 0 - полное несовпадение изображений, а 1 - их полное совпадение.

Последняя метрика перекрытия несколько менее распрастраненная - Symmetric Boundary DICE (SBD), описанной в работе \cite{yeghiazaryan2018family}.

Чтобы определить эту метрику необходимо ввести понятия \(r\) окрестности пикселя \(x\) и границы изображения.

Окрестностью радиуса \(r\) пикселя \(x \in P\) маски \(\tilde{\image}\) будем называть множество
\begin{equation}\label{eq:neighborhood}
    M_r(x) = \left\{ x' \in P \,\middle|\, \max_{i \in \{0,1,2\}} |x_i - x'_i| \leq r \right\},
\end{equation}
то есть все пиксели, находящиеся в дискретной окрестности Мура радиуса \(r\) от \(x\).

Размер этой окрестности напрямую влияет на чувствительность метрики: при малом  \(r\) метрика фиксирует только локальные несоответствия границ, а при большом — начинает учитывать отклонения на большем расстоянии, сглаживая мелкие ошибки.

Границей \(\partial \tilde{\image} \) маски \(\tilde{\image} \) будем называть множество пикселей, окрестность радиуса \(r\) которых содержит как пиксели фона, так и пиксели объекта:
\begin{equation}\label{eq:boundary}
    \partial \image = \{ x \in P | \exists x' \in M_r(x) : \tilde{\image}(x') = 0 \land  \exists x'' \in M_r(x) : \tilde{\image}(x'') = 1 \}
\end{equation}

Заметим,что так как метрики сравнивают бинарную маску \((\tilde{\image})_{seg}\) и эталонную маску \((\tilde{\image})_{gt}\) одного и того же исходного изображения, то у них одинаковая областль определения \(P\). 

Это позволяет выбрать одну окрестность радиуса \(r\) пикселя \(x\) и сравнивать значения пикселей из этого множества в обоих изображениях.

Обозначим через \(DICE(M_r(x))\) значение метрики dicе на множестве \(M_r(x)\): 
\begin{equation}
    DICE(M_r(x)) = DICE[(\tilde{\image})_{seg}(M_r(x)), (\tilde{\image})_{gt}(M_r(x))]
\end{equation}

Определив необходимые понятия можно перейти к определению метрики Symmetric Boundary DICE:
\begin{multline}\label{eq:SBD}
    SBD((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) = \\
    \frac{
        \sum\limits_{x \in \partial (\tilde{\image})_{seg}} DICE(M_r(x)) 
        + \sum\limits_{x \in \partial (\tilde{\image})_{gt}} DICE(M_r(x))
    }{
        |\partial (\tilde{\image})_{gt}| + |\partial (\tilde{\image})_{seg}|
    }
\end{multline}

В числителе формулы суммируются значения метрики Dice, вычисленные в окрестностях радиуса \(r\)  каждого граничного пикселя как сегментированной маски, так и эталонной. Знаменатель представляет собой общее количество таких граничных пикселей, обеспечивая нормировку результата. Параметр \(r\) задаёт радиус окрестности, используемой для локального сравнения, и определяется ранее в формуле~\eqref{eq:neighborhood}.

Следующая метрика в начальном наборе - метрика Normalized Hausdorff - отличается от предыдущих двух по принципу сравнения.

Данная метрика основана не на площади перекрытия, а на расстоянии между множествами объекта в сегментации и в эталонной бинарной маске. 

Чтобы определить метрику Normalized Hausdorff, определим расстояние между пикселем \(x \in P\) и множеством \((\tilde{\image}) = \{x | (\tilde{\image})(x) = 1\}\).

\begin{equation}\label{eq:setDistance}
    d(x,(\tilde{\image})) = inf_{y\in (\tilde{\image})} (\sqrt{(x_0 - y_0)^2 + (x_1 - y_1)^2 + (x_2 - y_2)^2})
\end{equation}

Операясь на формулу \ref{eq:setDistance} можно определить расстояние Хаусдорфа:

\begin{equation}\label{eq:HausdorffDistance}
    HD((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) = max(sup_{x \in (\tilde{\image})_{seg}}d(x, (\tilde{\image})_{gt}))
\end{equation}

Соответственно значением расстояния Хаусдорфа является максимум из минимумов расстояний от пикселя до множества объектов.

Определив все необходимые формулы можно определить метрику Normalized Hausdorff Distance:

\begin{equation}\label{eq:NormalizedHausdorffDistance}
    NHD((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) = 1 - \frac{max(HD((\tilde{\image})_{seg}, (\tilde{\image})_{gt}), HD((\tilde{\image})_{gt}, (\tilde{\image})_{seg}))}{\sqrt{n_0^2 + n_1^2 + n_2^2}}
\end{equation}

Максимальное значение расстояния Хаусдорфа в пределах изображения не превышает его диагонали, поэтому длина диагонали является разумным нормализующим коэффициентом.

Чем меньше значение расстояния Хаусдорфа, тем ближе бинарные маски друг к другу.

Для удобства интерпретации нормализованное расстояние вычитается из единицы, поэтому метрика Normalized Hausdorff Distance принимает значения от 0 (полное несовпадение) до 1 (полное совпадение масок).

Последней метрикой в начальном наборе является MSE - среднеквадратичное расстояние между пикселями сравниваемых масок.

\begin{equation}\label{eq:MSE}
    MSE((\tilde{\image})_{seg}, (\tilde{\image})_{gt}) = \frac{1}{n_0 \cdot n_1 \cdot n_2} \sum_{x \in P} ((\tilde{\image})_{seg}(x) - (\tilde{\image})_{gt}(x))^2
\end{equation}

Таким образом, начальный набор метрик составлен из метрик, различных по принципу их оценки.

Следующим шагом в формировании итогового набора метрик является составление набора эталонных изображений для оценки чувствительности начального набора к различным видам ошибок.

Будем рассматривать в качестве типовых ошибок ''Рябь'', соответствие границ объекта, ''Выброс'' и ошибки при преобладании объекта над фоном.

''Рябь'' будем определять как наличие фоновых пикселей, ошибочно попавших в область объекта.

Ошибка соответствия границ возникает в тех случаях, когда сегментированная область в целом совпадает с объектом, но границы объекта смещены относительно эталона. 

Следующим типом ошибок является ''Выброс'' - некоторое небольшое количество пикселей ошибочно классифицированные как объект, при этом находящихся на расстоянии от области объекта.

Последей ситуацией, на которой будем проводить опыты над метриками, является преобладание объекта над фоном. 

В такой ситуации некоторые метрики могу быть менее чувствительными к ошибкам так как в пбсолютных цифрах большинство изображения является объектам. На пример это может привести к хорошей оценке нечувствительной метрикой если просто классифицировать все изображения как объект.

Модельные изображения, на которых будут проводиться эксперименты с метриками, приведены в рисунке~\ref{fig:testsmetrics}.

\gostfigure{testsmetrics}{Тестовое изображение для экспериментов по оценке чувствительности метрик; а — эталонная маска,
б — тест ''Рябь'',
в — тест ''Соответствие границ''
г — тест ''Выброс''
д — тест ''Преобладание объекта над фоном'',
е — эталонная маска для теста ''Преобладание объекта над фоном''
}{testsmetrics}

Собрав начальный набор метрик, определив типы ошибок и модельные изображения, можно провести эксперименты по оценке чувствительности метрик.

Эксперименты реализованы с помощью языка программирования Python с использованием библиотек numpy для работы с изображениями как с многомерным массивом, PIL для операций чтения и записи изображений в файловой системе, а также matplotlib для визуализации результатов.

Настройки экспериментов читаются с файла формата JSON, который представляет собой массив из объектов, описывающих эксперимент. 

Каждый объект описания эксперимента содержит его название и пути к модельному и эталонному изображениям.

Программа сравнивает по каждой метрике модельные изображения с эталонными и записывает результат в таблицу, столбцы которой являются значениями метрик, а строки соответствуют экспериментам.

Заполнив таблицу с резульататами программа выводит ее визуализацию в виде табличной тепловой карты.

Получившаяся в результате экспериментов тепловая карта представлена на рисунке \ref{fig:metricsexperiment}.

\gostfigure{metricsexperiment}{Тепловая карта значений метрик для модельных изображений с различными типами ошибок. Цвет и числа отражают чувствительность метрик к отклонениям от эталона.}{metricsexperiment}

Сравнение значений метрик показывает, что IOU и DICE в целом демонстрируют схожее поведение на различных типах ошибок, однако IOU в большинстве случаев оказывается более чувствительной. Сответственно в итоговый набор метрик имеет смысл включить IOU и исключить DICE.

Symmetric Boundary DICE показывает высокую чувствительность к ошибкам соответсвия границ, ''Ряби'' и ошибкам при преобладании объекта над фоном. 

Метрика MSE реагирует на все виды ошибок, однако её показания в совокупности дублируются метриками IOU и Symmetric Boundary DICE, что делает её избыточной в составе итогового набора.

Для ошибки типа ''Выброс'' все метрики показывают сравнительно низкую чувствительность, однако наилучшие результаты наблюдаются у метрик IOU и Symmetric Boundary DICE.

В итоговый набор метрик включены IOU и Symmetric Boundary DICE. Первая представляет собой компактную и широко используемую метрику перекрытия, служащую ориентиром для оценки общей точности сегментации, а вторая — наиболее чувствительна к локальным погрешностям и искажениям границ.

Собрав набор данных, алгоритмы и метрики можно приступить к проектированию и реализации конвейера основных экспериментов.

\subsection{Проектирование и реализация программного комплекса конвейера экспериментов}

Проектирование и реализация эффективного программного обеспечения начинается с чёткой постановки требований, поэтому первым шагом в разработке конвейера экспериментов является их формулировка.

Первым требованием к конвейеру является устойчивость к прерыванию.

Система должна обеспечивать возможность продолжения экспериментов с места остановки, поэтому результаты уже выполненных вычислений необходимо сохранять, чтобы при последующем запуске можно было продолжить выполнение без необходимости пересчёта уже обработанных данных.

Следующим требованием к конвейеру экспериментов является модульность — система должна позволять легко добавлять новые данные, алгоритмы и метрики без необходимости переработки остального кода.

 Такая гибкость особенно важна при проведении серии экспериментов, где может потребоваться быстро изменять состав компонентов для оценки их влияния на итоговый результат.

Последним требованием к конвейеру является поддержка вычислений на графическом процессоре.

Многие используемые алгоритмы и метрики допускают параллельную обработку, поэтому реализация с возможностью использования дискретной видеокарты позволяет существенно ускорить вычисления и сократить общее время экспериментов.

Конвейер экспериментов был спроектирован с учетом вышесформулированных требований.

Система конвейера экспериментов будет состоять из пяти модулей:
 
\begin{enumerate}
    \item Модуль реконструкции
    \item Модуль бинаризации
    \item Модуль оценки результатов
    \item Модуль визуализации результатов
\end{enumerate}

Рассмотрим подробнее каждый из этих модулей и сформулируем их входные данные, выход и особенности реализации.

Модуль реконструкции отвечает за симуляцию томографии под контролем реконструкции.

На вход этому модулю требуется трёхмерное изображение в виде набора двумерных срезов, а также файл с настройками, содержащий название изображения, путь к эталонной маске и параметры для выполнения реконструкции.

Кроме того, модулю передаются общие параметры эксперимента: стратегия выбора углов проекций и их максимальное количество.

К числу параметров реконструкции относятся, в частности, размеры проекционного детектора, задаваемые числом строк и столбцов, а также шаг детектора по осям, определяющий физический размер пикселя. Эти параметры влияют на масштаб и разрешение моделируемых проекционных данных. Также указывается используемый алгоритм реконструкции; если он является итеративным, дополнительно задаётся количество итераций, определяющее глубину восстановления.

На выходе модуль формирует реконструкции для каждого набора углов проекций и сохраняет их в формате TIFF, а также некоторые параметры и значение, которые понадобятся для следующего модуля.

Такими параметрами являются путь к эталонной маске, среднеквадратичное отклонение уровня шума в реконструкции, название исходного изображения, индекс набора углов и массив с углами в радианах.

Результаты сохраняются в директории с установленной структурой: для каждого входного изображения создаётся отдельная папка, имя которой совпадает с названием изображения. Внутри неё размещаются подкаталоги, пронумерованные от  0 до \(n\), где \(n\) - количество наборов углов. Каждый из этих подкаталогов содержит изображение реконструкции, полученное на основе соответствующего набора углов.

С целью обеспечения устойчивости к прерыванию каждая реконструкция сохраняется сразу после завершения расчёта. При повторном запуске модуль проверяет наличие соответствующего результата в папке и, если он уже существует, пропускает данный набор углов.

Модуль считывает входные данные из заданной директории, в которой должны располагаться подкаталоги — по одному на каждое изображение. Каждый такой подкаталог содержит срезы изображения и файл с его настройками.

Такой способ организации данных позволяет легко добавлять или удалять входные изображения без изменения исходного кода, что соответствует требованию модульности.

Реализация модуля выполнена на языке Python. Для моделирования процесса томографии под контролем реконструкции используется библиотека astra-toolbox \cite{van2016fast}, поддерживающая, в том числе, выполнение реконструкции на графическом процессоре.

Модуль бинаризации реализует бинарную сегментацию каждого входного изображения с помощью заданного набора алгоритмов.

Входными данными для модуля являются реконструкции, полученные на предыдущем этапе, а также параметры, необходимые для настройки алгоритмов бинаризации.

Работа модуля организована следующим образом: производится обход директории с результатами модуля реконструкции. Для каждой вложенной папки — соответствующей конкретному изображению и набору углов — считываются файл реконструкции в формате TIFF и сопутствующие параметры, сохранённые на этапе реконструкции.

Затем для каждой полученной реконструкции последовательно применяются все алгоритмы из заданного набора.

Набор алгоритмов формируется из папки algorithms, в которой должны быть файлы с реализацией алгоритма сегментации. Реализация должна содержать метод segment, принимающий на вход изображение реконструкции и эталонную маску. На выходе функция segment должна вернуть бинаризацию и объект с значениями параметров, используемых алгоритмом бинаризации. 

Таким образом, требование модульности выполняется: для добавления или удаления алгоритма достаточно поместить или удалить соответствующий файл из директории algorithms, без необходимости внесения изменений в остальной код конвейера.

После выполнения бинаризации полученная маска сохраняется в формате TIFF в папке, путь к которой включает название изображения, индекс набора углов и имя алгоритма. В той же папке дополнительно сохраняется JSON-файл, содержащий параметры, использованные при бинаризации, путь к соответствующей эталонной маске, а также список с набором углов проекций, использованных при реконструкции входного изображения.

В целях обеспечения устойчивости алгоритма к прерыванию, при запуске производится проверка на существования путя к результатам и наличия там уже готовой бинаризации. При обнаружении таких файлов изображение пропускается. 

Модуль реализован на языке Python с использованием библиотеки CuPy \cite{cuPy}, предоставляющей реализации базовых численных операций, таких как свёртки и тензорные преобразования, на графическом процессоре с поддержкой CUDA. 

Благодаря этому становится возможным эффективно использовать графический процессор для ускорения алгоритмов бинаризации, поскольку многие из них хорошо поддаются параллелизации.

Далее рассмотрим модуль оценки результатов. Этот модуль отвечает за вычисление значений метрик, характеризующих качество полученных бинаризаций.

Работа модуля организована как последовательный обход структуры папок, сформированной предыдущим этапом. В каждой вложенной директории он поочерёдно обрабатывает результаты бинаризации: загружает бинарную маску и соответствующий JSON-файл с параметрами, содержащими путь к эталонной маске, параметры алгоритма бинаризации и набор углов проекций.

После загрузки данных модуль рассчитывает значения всех метрик из заданного набора и сохраняет результат в CSV-файл. Структура путей при этом сохраняется аналогично результатам бинаризации, но с другой корневой директорией, соответствующей модулю оценки.

При этом модуль оценки совершает рассчет метрик в двух режимах - по эталону и по соседней бинаризации.

В режиме эталона значение метрики бинаризации рассчитывается в сравнении с эталонной маской. 

В режиме соседней бинаризации значение метрики текущей бинаризации рассчитывается по сравнению с бинаризацией предыдущей реконструкции того же изображения.

Предыдущей реконтрукцией считаем рекнострукцию изображения по набору углов с индексом на 1 меньше чем индекс набора углов текущей реконструкции. 

Соответственно в режиме соседней бинаризации рассчет метрик начинается с бинаризации реконструкции, полученной из набора угла с индексом 1 и таких значений будет на единицу меньше, чем в режиме эталона.

Обработка выполняется поэтапно: каждая бинаризация обрабатывается отдельно, результаты сохраняются сразу после расчёта. 

При этом, перед рассчетом метрик, программа также проверяет наличие CSV файла в дерикториии с результатами, соответствующей текущей входной бинарной маске. Если таковой существует - то программа пропускает данное изображение.

Такой подход обеспечивает устойчивость к прерыванию и позволяет избежать повторной обработки уже обработанных данных.

Аналогично предыдущему модулю, набор метрик формируется на основе содержимого директории metrics, в которой располагаются файлы с их реализациями. Название каждой метрики соответствует имени соответствующего файла. Каждый такой файл должен содержать функцию evaluate, принимающую на вход бинарную маску и эталонную маску, и возвращающую численное значение метрики.

Стоит также отметить, что метрика Symmetric Boundary DICE требует параметра \(r\) - радиуса окрестности граничных пикселей~\eqref{eq:SBD}.

В целях простоты реализации в качестве значения параметра было выбрано \(r = 5\). 

Модуль был написан на языке Python с использованием библиотеки CuPy, позволяющей ускорить вычисления метрик с помощью графического процессора.

Последним модулем конвейера экспериментов является модуль визуализации. Его задача — агрегировать полученные результаты и представить их в наглядной графической форме.

Модуль считывает все CSV-файлы, сформированные на предыдущем этапе, из директории с результатами. В отличие от других модулей, он не обрабатывает файлы по одному, а загружает все данные сразу. Для удобства доступа и группировки реализован интерфейс ResultData, обеспечивающий получение результатов в различных представлениях — например, значения метрик по алгоритмам, по изображениям и другим признакам.

Такая конструкция позволяет программе соответствовать требованию модульности: для добавления новой визуализации достаточно разместить соответствующий файл с реализацией в директории visualizators, без необходимости внесения изменений в основной код.

Модуль реализован на языке python с применением библиотек numpy для работы с массивами данных и matplotlib для формирование графиков.

Применение графического процессора в рамках данного модуля избыточно, соответственно все операции проиходят на центральном процессоре.

В реализации конвейера также присутствует контрольный модуль, который последовательно запускает другие модули. Он необходим так как все другие модули спроектированы как отдельные программы.

Таким образом, в данной главе были рассмотрены все основные компоненты, необходимые для построения эксперимента по исследованию итеративной томографии под контролем реконструкции: входной набор данных, алгоритмы сегментации, метрики оценки качества и программный конвейер. 

В следующей главе будет сформулировано правило останова процесса томографии под контролем реконструкции на основе анализа бинаризаций. С помощью разработанного конвейера экспериментов будут проведены эксперименты по исследованию его эффективности.